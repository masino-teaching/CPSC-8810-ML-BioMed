{"cells":[{"cell_type":"markdown","metadata":{"id":"Q2o5Y2hCqF7U"},"source":["# Practicum 03 - Classification with Structured Biomedical Data\n","\n","In this practicum, we apply classification models on the dataset [HCV](https://archive.ics.uci.edu/dataset/571/hcv+data). Per the [UCI website](https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset), the dataset __\"contains laboratory values of blood donors and Hepatitis C patients and demographic values like age\"__. Specifically, there are 12 predictor variables that include age, sex, and 10 laboratory measurements that are known to be associated with Hepatitis C presence and stage. __Our goal is to develop classification models that can accurately predict if a potential blood donor has Hepatitis C or not.__. In the published paper by [Hoffmann et al.](https://jlpm.amegroups.org/article/view/4401/5425), the authors developed a multiclass model to predict Hepatitis stage. We will simplify the problem here to one of binary classification in which we will predict if the potential donor either has Hepatitis or not. We will develop a logistic regression model using [scikit-learn](https://scikit-learn.org/stable/index.html) and a gradient boosted tree model using [catboost](https://catboost.ai/).\n","\n","Before working with the HCV data, we will first illustrate the model development and evaluation approaches using a simulated dataset.\n","\n","This practicum will implement some of the concepts discussed in the two previous lectures, _Logistic Regression_ and _Tree-based classification_. Specifically we: will\n","-  Demonstrate logistic regression classification on a simulated dataset\n","-  Apply logistic regression classification to the _HVC_ dataset\n","-  Demonstrate gradient boosting trees on the same simulated dataset\n","-  Apply gradient boosting trees to the _HVC_ datest\n","-  Examine standard performance metrics on all models"]},{"cell_type":"code","source":["# Google Colab setup\n","# mount the google drive - this is necessary to access supporting src\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"Qw-w7qaKqJaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# install any packages not found in the Colab environment\n","!pip install ucimlrepo\n","!pip install catboost"],"metadata":{"id":"81tO23P8qNgx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1u1oV_TgqF7W"},"outputs":[],"source":["# imports\n","from ucimlrepo import fetch_ucirepo\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, confusion_matrix,  ConfusionMatrixDisplay, RocCurveDisplay, PrecisionRecallDisplay\n","import numpy as np\n","import catboost as cb\n","\n","# local project imports\n","import sys\n","sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/CPSC-8810-ML-BioMed/src\")\n","from plotting import plt_box_grid_by_target, plt_box_grid, plt_xy_scatter_grid\n","from uci_utils import get_vars_of_type\n","from regression_util import plot_fitted_resids, plot_outliers, plot_leverage\n","from filter import correlation_filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cACu0ZUaqF7W"},"outputs":[],"source":["# global settings\n","pd.options.display.max_columns = 100\n","rs = 654321 # random state, use this to ensure reproducibility"]},{"cell_type":"markdown","metadata":{"id":"AI_8FXXSqF7W"},"source":["# Simulated data\n","\n","To get started, let's generate simulated data for classification. We will use this data to illustrate classification model development and evaluation process using both logistic regression and gradient boosting tree classificaiton approaches.\n","\n","To generate the simulated data, we use the `make_classification` method from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#). For demonstration, we will split the data into training and test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpNYaq-UqF7W"},"outputs":[],"source":["# generate simulated classification data\n","n = 250 # number of samples\n","n_train = 200 # number of training samples\n","balance = 0.4 # fraction of negative class\n","X, y = make_classification(n_samples=n, n_features=10, n_informative=8, n_redundant=2,\n","                           n_classes=2, n_clusters_per_class=2,\n","                           flip_y=0.01, class_sep=1.0, hypercube=True, weights=[balance, 1-balance],\n","                           shift=0.0, scale=1.0, shuffle=True, random_state=rs)\n","# for plotting purposes, let's convert to a dataframe\n","df = pd.DataFrame(X, columns=[f'x{i}' for i in range(1, 11)])\n","df['target'] = y\n","\n","# split into train and test\n","X_train = X[:n_train]\n","y_train = y[:n_train]\n","X_test = X[n_train:]\n","y_test = y[n_train:]"]},{"cell_type":"markdown","metadata":{"id":"tKiZ9zD9qF7X"},"source":["Let's make a bar plot of the target variable to see the distribution of the target class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kpGGCO_UqF7X"},"outputs":[],"source":["# count plot of the target variable\n","sns.countplot(df, x='target')"]},{"cell_type":"markdown","metadata":{"id":"mVOjYbQ4qF7X"},"source":["Next, let's generate boxplots of the predictor features grouped by the class label, $y$. This will give us a sense of the inter-class distribution differenecs for each feature. We should expect to see that most of the features will have different means and IQR indicating an assocation between the feature and the outcome class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"glfsw63yqF7X"},"outputs":[],"source":["# put X and y in a pandas dataframe, then create a grid of boxplots showing the distribution of each feature in the training data segmented by the target\n","plt_box_grid_by_target(df, target_label='target', num_cols=5, fig_size=(16,9));"]},{"cell_type":"markdown","metadata":{"id":"c3m8BwEIqF7X"},"source":["# Logistic Regression Models\n","## Simulated data model\n","\n","Let's start by fitting a logistic regression classifier model to the simulated data. We will use the [scikit-learn Logistic Regression module](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) to create the model. We will rely on the default parameters which include _l2 regularization_. Later in the course, we will discuss hyperparameter selection approaches where we will modify the default values. Here, we fit the model to the _training data_."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Bl_OGK7qF7X"},"outputs":[],"source":["clf = LogisticRegression(random_state=rs).fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"N712I1ZkqF7X"},"source":["Now let's examine the perforamnce on the test set. Let's start by looking at the confusion matrix. In the confusion matrix, we see the counts of __true negative__ and __positive predictions__ in the __top left__ and __bottom right corners__, respectively. We see the counts of __false positive__ and __false negative__ predictions in the top right and bottom left corners, respectively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeCtO5NAqF7X"},"outputs":[],"source":["y_pred = clf.predict(X_test)\n","target_names = ['class 0', 'class 1']\n","cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n","disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n","disp.plot(cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"GVNsmlN2qF7X"},"source":["Now let's examine some of the common point metrics used to evaluate classifier performance. We will use the [scikit-learn classification_report module](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) to generate a summary of the performance metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4S2mgQHqF7X"},"outputs":[],"source":["print(classification_report(y_test, y_pred, target_names=target_names))"]},{"cell_type":"markdown","metadata":{"id":"pz2UITNcqF7X"},"source":["To keep the table small and accomodate multiclass scenarios, scikit-learn presents _intraclass_ metrics. Let's break these down sarting with the first two rows. Let _P_ be the number of postive samples, _N_ be the number of negative samples, _TP_ be the number of true postives (correctly predicted postives), _FP_ be the number of false postives, let _TN_ be the number of true negatives (correctly predicted negatives), and _FN_ be the number of false negatives:\n","- __class 0 precision ($C_0P$)__: equal to _TN/N=TN_/(_TN_+_FN_) also known as _negative predictive value_ (NPV)\n","- __class 0 recall ($C_0R$)__: equal to _TN_/(_TN_+_FP_) also known as _specificity_\n","- __class 0 f1-score__ : equal to $2\\frac{C_0P\\times C_0R}{C_0P+C_0R}$\n","- __class 1 precision ($C_1P$)__: equal to _TP/P=TP_/(_TP_+_FP_) typically known\n","- __class 1 recall ($C_1R$)__: equal to _TP_/(_TP_+_FN_) also known as _specificity_\n","- __class 1 f1-score__ : equal to $2\\frac{C_1P\\times C_1R}{C_1P+C_1R}$\n","\n","The _accuracy_ row is simply the overall model accuracy = (TP+TN)/(P+N)\n","\n","The _macro avg_ row is the unweighted average over the class metric scores for each class. For example, the _macro avg precision_ = $\\frac{1}{2}(C_0P + C_1P$). The _macro avg_ treats all classes equally.\n","\n","The _weighted avg_ row is similar to to the _macro _avg_ but weights each class metric score by the support proportion. For example, the _macro avg precison_ = $\\frac{1}{50}(16C_0P + 34C_1P)$"]},{"cell_type":"markdown","metadata":{"id":"5p8igtj-qF7X"},"source":["Next, let's look at the _Reciever Operating Characteritic_ curve which tells us how well the model can trade off between recall (a.k.a. sensitivity or TPR) and specificity = 1 - FPR as the decision threshold (the probability value of the postive class above which we decide the input belongs to the postive class). Ideally, we seek a model where the precision recall curve rises sharply to 1.0 on the y-axis and doesn't decline). The _Area Under the ROC Curve_ (AUC) is a summary statistic for the ROC. The optimal value of AUC is 1.0. We can generate the plot directly from the model using the [scikit-learn RocCurveDisplay module](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html). As we expected from the confusion matrix, the model performs very well in terms of the ROC."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qw8LkqgMqF7Y"},"outputs":[],"source":["# Plot the ROC\n","RocCurveDisplay.from_estimator(clf, X_test, y_test)\n","plt.grid()"]},{"cell_type":"markdown","metadata":{"id":"Z0Xvx5mzqF7Y"},"source":["Finally, let's look at the _Precision Recall_ curve which tells us how well the model can trade off between recall and precision (a.k.a. positive predictive value). In cases of strong class imbalance (i.e., where there are many more samples in one class than the other for binary classification), the PR curve is a better measure of performance than the ROC. Similar to the AUC, the _average precision_ (AP) is a point metric that summarizes the PR curve with the optimal value being 1.0. We can generate the plot directly from the model using the [scikit-learn PrecisionRecallDisplay module](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.PrecisionRecallDisplay.html#sklearn-metrics-precisionrecalldisplay). Again, we see that this model has good PR performance as we expected from the confusion matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkdWquKbqF7Y"},"outputs":[],"source":["PrecisionRecallDisplay.from_estimator(clf, X_test, y_test)\n","plt.grid()"]},{"cell_type":"markdown","metadata":{"id":"HJqu1YKxqF7Y"},"source":["# Logistic Regression Model for HCV data\n","\n","Now, let's apply the logistic regression model analysis to the [HCV](https://archive.ics.uci.edu/dataset/571/hcv+data). Our goal is to use the features of this data set to predict whether the potential blood donor has Hepatitis C or not.\n","\n","The predictors for this dataset include demographics and several blood test features .\n","\n","In a complete model development process, we would explore the dataset as we did in Practicum 1. In the interest of time, here we will proceed directly to model development. You are encouraged to use the lessons of Practicum 1 and the above data exploration techniques for the simulated dataset to explore this dataset.\n","\n","Before developing our model, we will need to:\n","1. Pull the data from the UCI website\n","2. Address any missing data\n","3. Address feature cross-correlation\n","4. Standardize features\n","5. This dataset does not have categorical features, so we will not need to create dummy values.\n","We will address these concerns in more detail in future lectures. For now, we will address missing data by dropping incomplete cases. We will address feature cross-correlation by dropping one feature from any pair that has a correlation coefficient >0.95. Finally, we will standardize continuous features as we did in practicum 1.\n","\n","Once these steps are completed, we will complete the following:\n","1. Fit an logistic regression classification model to the training data.\n","2. Assess performance on the test set using point metrics, ROC and PR curves."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6jgphDrqF7Y"},"outputs":[],"source":["# fetch dataset\n","hcv_data = fetch_ucirepo(id=571)\n","\n","# data (as pandas dataframes)\n","X = hcv_data.data.features.dropna().copy()\n","X['Sex_male'] = [1 if x=='m' else 0 for x in X.Sex] # convert to binary from string\n","X.drop(columns=['Sex'], inplace=True) # drop the original column\n","\n","# converting this to a binary classification problem where the\n","# positive class is hepatitis, fibrosis, or cirrhosis\n","y = hcv_data.data.targets.loc[X.index].isin(['1=Hepatitis', '2=Fibrosis', '3=Cirrhosis']).astype(int)\n","meta_vars = hcv_data.variables\n","\n","# split the data into train and test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rs)\n","\n","# standardize the continuous features\n","continuous_vars, X_train_continuous = get_vars_of_type(X_train, meta_vars, var_type_key = 'type', var_name_key = 'name', type_kw = 'Continuous')\n","scaler = preprocessing.StandardScaler().fit(X_train_continuous)\n","X_train_continuous_scaled = scaler.transform(X_train_continuous)\n","# note we use the same scaler for the test data to prevent data leakage\n","continuous_vars, X_test_continuous = get_vars_of_type(X_test, meta_vars, var_type_key = 'type', var_name_key = 'name', type_kw = 'Continuous')\n","X_test_continuous_scaled = scaler.transform(X_test_continuous)\n","\n","# this dataset does not contain any categorical features\n","\n","# combine the continuous and categorical features\n","X_train_new_lr = pd.DataFrame(X_train_continuous_scaled, columns=X_train_continuous.columns)\n","X_test_new_lr = pd.DataFrame(X_test_continuous_scaled, columns=X_train_continuous.columns)\n","y_train_new_lr = y_train.reset_index(drop=True)\n","y_test_new_lr = y_test.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"teeraN6oqF7Y"},"source":["# Problem 1 (1 point)\n","In the code cell below, (1) use the scikit-learn `LogisticRegression` module to fit a logistic regression model to the HVC data using the `X_train_new_lr` and `y_train_new_lr` variables. Store the fit model in the `clf` variable; and (2) generate the model predictions on the test set `X_test_new_lr`. Store the model predictions in the `y_pred` variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXo89z5dqF7Y"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","clf = None\n","y_pred = None"]},{"cell_type":"markdown","metadata":{"id":"KPnfAtz4qF7Y"},"source":["Now let's look at the confusion matrix to get an initial assessment of the model performance on the HVC test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AY29Z7ClqF7Y"},"outputs":[],"source":["target_names = ['blood donor', 'hepititis']\n","cm = confusion_matrix(y_test_new_lr, y_pred, labels=clf.classes_)\n","disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n","disp.plot(cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8x6FEH9FqF7Y"},"source":["# Problem 2 (1 point)\n","\n","Now let's generate some formal performance metrics. First, let's view the standard point metrics. In the code cell below, use the `y_test_new_lr` and `y_pred` variables to print the _classification report_ from scikit-learn. It will make the table easier to read if you provide the `target_names` keyword argument using the target names as in the confusion matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZJxNvKoqF7Y"},"outputs":[],"source":["################# YOUR CODE HERE ##################"]},{"cell_type":"markdown","metadata":{"id":"qe5rhB-xqF7Y"},"source":["# Problem 3 (1 point)\n","Finally, let's examine the Reciever Operating Chracteristic curve and the Precision Recall Curve. In the two code cells below, plot the ROC and PR on the test data, `X_test_new_lr` and `y_test_new_lr` for the logistic regression classifer `clf`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uT20QVCvqF7Y"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","# Plot the ROC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tXDHqXtPqF7Y"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","# Plot the PR"]},{"cell_type":"markdown","metadata":{"id":"t_Bgb3oCqF7Y"},"source":["# Tree-based Classification Models using CatBoost\n","\n","## Simulated data model\n","\n","Let's now investigate a tree-based model. As in Practicum 2, we will use the [CatBoost.ai](https://catboost.ai/) library to create a boosted gradient tree ensemble model.  For more details on the implementation see the original [CatBoost paper](https://arxiv.org/abs/1706.09516).\n","\n","First, let's recreate our simulated data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvJ9EWZgqF7Y"},"outputs":[],"source":["X, y = make_classification(n_samples=n, n_features=10, n_informative=8, n_redundant=2,\n","                           n_classes=2, n_clusters_per_class=2,\n","                           flip_y=0.01, class_sep=1.0, hypercube=True, weights=[balance, 1-balance],\n","                           shift=0.0, scale=1.0, shuffle=True, random_state=rs)\n","\n","# split into train and test\n","X_train = X[:n_train]; y_train = y[:n_train]; X_test = X[n_train:]; y_test = y[n_train:]\n","train_dataset = cb.Pool(X_train, y_train)\n","test_dataset = cb.Pool(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"ft0e0iCgqF7Y"},"source":["We can now fit a gradient boosted tree model to the simulated data using the [CatBoostClassifier module](https://catboost.ai/en/docs/concepts/python-reference_catboostclassifier). As with the scikit-learn logistic regression classifer, the CatBoost classifier module has numerous tuning parameters. Here, we will use the default parameters, again noting that in later sessions, we will instead prefer to optimize these tuning parameters using a systematic approach."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dB3ZlB5kqF7Y"},"outputs":[],"source":["cb_clf = cb.CatBoostClassifier(random_seed=rs, verbose=False)\n","cb_clf.fit(train_dataset)"]},{"cell_type":"markdown","metadata":{"id":"F0405pOhqF7Y"},"source":["Just as in the logistic regression model, once we have fit the model with the training data, we can use it to predict the class labels for the test data using the `predict` method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qk7KvZPlqF7Z"},"outputs":[],"source":["y_pred = cb_clf.predict(X_test)"]},{"cell_type":"markdown","metadata":{"id":"fQg93hoCqF7Z"},"source":["Now let's examine the perforamnce on the test set. __Fortunately, the CatBoost API uses the same conventions as scikit-learn, and so we can use all the scikit-learn peformance assessment modules directly on the CatBoost model object `cb_clf` and the test set predictions, `y_pred`.__\n","\n","Let's start by looking at the confusion matrix. We can see that the CatBoost model effecitively does the same as the logistic regression model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d46yZt9eqF7Z"},"outputs":[],"source":["target_names = ['class 0', 'class 1']\n","cm = confusion_matrix(y_test, y_pred, labels=cb_clf.classes_)\n","disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n","disp.plot(cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fF1qDWrHqF7j"},"source":["Next let's examine the point metric values for the CatBoost model using the sklearn `classification_report` module."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMPSobhrqF7j"},"outputs":[],"source":["print(classification_report(y_test, y_pred, target_names=target_names))"]},{"cell_type":"markdown","metadata":{"id":"jmalI4rrqF7j"},"source":["Finally, let's examine the ROC and PR curves for the CatBoost model. Not surprisingly, we see that the model has achieved nearly optimal performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-ekkjHWqF7j"},"outputs":[],"source":["# Plot the ROC\n","RocCurveDisplay.from_estimator(cb_clf, X_test, y_test)\n","plt.grid()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2BOsC81qF7j"},"outputs":[],"source":["PrecisionRecallDisplay.from_estimator(cb_clf, X_test, y_test)\n","plt.grid()"]},{"cell_type":"markdown","metadata":{"id":"4sfYkZy7qF7j"},"source":["# CatBoost Classifier for HCV Data\n","\n","Now, let's apply the gradient boosted tree model analysis to the [HCV](https://archive.ics.uci.edu/dataset/571/hcv+data) dataset. We will first reload the dataset. Notice two important items here:\n","1. Because we are using decision trees we do not need to standardize the variables. Recall, there are no weights applied to the inputs, rather only cutpoints need to be selected.\n","2. There are no categorical variables in this dataset.\n","\n","As with the simulated data, we use the CatBoost `Pool` class to construct training and testing pools."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ed1QTIrYqF7j"},"outputs":[],"source":["# fetch dataset\n","hcv_data = fetch_ucirepo(id=571)\n","\n","# data (as pandas dataframes)\n","X = hcv_data.data.features.dropna()\n","X = hcv_data.data.features.dropna().copy()\n","X['Sex_male'] = [1 if x=='m' else 0 for x in X.Sex] # convert to binary from string\n","X.drop(columns=['Sex'], inplace=True) # drop the original column\n","# converting this to a binary classification problem where the\n","# positive class is hepatitis, fibrosis, or cirrhosis\n","y = hcv_data.data.targets.loc[X.index].isin(['1=Hepatitis', '2=Fibrosis', '3=Cirrhosis']).astype(int)\n","meta_vars = hcv_data.variables\n","\n","# split the data into train and test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=rs)\n","\n","# there are no categorical variables in this dataset\n","# create the catboost datasets\n","train_dataset = cb.Pool(X_train, y_train, cat_features=None)\n","test_dataset = cb.Pool(X_test, y_test, cat_features=None)"]},{"cell_type":"markdown","metadata":{"id":"Fb4Sh-2eqF7j"},"source":["# Problem 4 (1 point)\n","In the code cell below, (1) use the CatBoost `CatBoostClassifier` module to fit a boosted tree model to the HVC data using the `train_dataset` pool variable. Store the fit model in the `cb_clf` variable; and (2) generate the model predictions on the test set `test_dataset` pool variable. Store the model predictions in the `y_pred` variable."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4xmyKoktqF7j"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","cb_clf = None\n","y_pred = None"]},{"cell_type":"markdown","metadata":{"id":"kHabOrpjqF7j"},"source":["Now let's look at the confusion matrix to get an initial assessment of the model performance on the HVC test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pb_0G46aqF7j"},"outputs":[],"source":["y_pred = cb_clf.predict(X_test)\n","target_names = ['blood donor', 'hepititis']\n","cm = confusion_matrix(y_test, y_pred, labels=cb_clf.classes_)\n","disp = ConfusionMatrixDisplay(cm, display_labels=target_names)\n","disp.plot(cmap='Blues')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"x9Je1eeIqF7j"},"source":["# Problem 5 (1 point)\n","\n","Now let's generate some formal performance metrics for the CatBoost classifier. First, let's view the standard point metrics. In the code cell below, use the `y_test` and `y_pred` variables to print the _classification report_ from scikit-learn. It will make the table easier to read if you provide the `target_names` keyword argument using the target names as in the confusion matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOFU32CpqF7j"},"outputs":[],"source":["################# YOUR CODE HERE ##################"]},{"cell_type":"markdown","metadata":{"id":"EXHdiNzDqF7j"},"source":["# Problem 6 (1 point)\n","Finally, let's examine the Reciever Operating Chracteristic curve and the Precision Recall Curve. In the two code cells below, plot the ROC and PR on the test data, `X_test` and `y_test` for the CatBoost classifer `cb_clf`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7_n3Oc6qF7j"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","# Plot the ROC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOpZeU3HqF7j"},"outputs":[],"source":["################# YOUR CODE HERE ##################\n","# Plot the PR"]}],"metadata":{"kernelspec":{"display_name":"cpce8810","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}